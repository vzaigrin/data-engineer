{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@1845b51a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@1845b51a"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession\n",
    "    .builder\n",
    "    .appName(\"spark-model\")\n",
    "    .config(\"spark.driver.cores\", \"5\")\n",
    "    .config(\"spark.driver.memory\", \"8g\")\n",
    "    .config(\"spark.executor.cores\", \"5\")\n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\")\n",
    "    .config(\"spark.memory.offHeap.size\", \"32g\")\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 2.4.4\n"
     ]
    }
   ],
   "source": [
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|800000|\n",
      "|    0|800000|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataSchema = StructType(StructField(target,IntegerType,true), StructField(id,LongType,true), StructField(raw_timestamp,StringType,true), StructField(query_status,StringType,true), StructField(author,StringType,true), StructField(tweet,StringType,true))\n",
       "dataPath = /home/jovyan/data/training.1600000.processed.noemoticon.csv\n",
       "raw_sentiment = [label: int, tweet: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"target\", IntegerType)\n",
    "    .add(\"id\", LongType)\n",
    "    .add(\"raw_timestamp\", StringType)\n",
    "    .add(\"query_status\", StringType)\n",
    "    .add(\"author\", StringType)\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "    \n",
    "val dataPath= \"/home/jovyan/data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "val raw_sentiment = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\",false)\n",
    "    .schema(dataSchema)\n",
    "    .load(dataPath)\n",
    "    .selectExpr(\"(case when target=4 then 1 else 0 end) as label\",\"tweet\")\n",
    "\n",
    "raw_sentiment.groupBy($\"label\").count.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Train-Validation Split to get better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training = [label: int, tweet: string]\n",
       "test = [label: int, tweet: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(training, test) = raw_sentiment.randomSplit(Array(0.9, 0.1), seed = 12345)\n",
    "training.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer = tok_ac27dce37eaf\n",
       "hashingTF = hashingTF_1e1a6b41b7dd\n",
       "rf = rfc_c5d3f6700f16\n",
       "pipeline = pipeline_e9786cc35e88\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_e9786cc35e88"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
    "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "val tokenizer = new Tokenizer()\n",
    "    .setInputCol(\"tweet\")\n",
    "    .setOutputCol(\"words\")\n",
    "\n",
    "val hashingTF = new HashingTF()\n",
    "    .setNumFeatures(1000)\n",
    "    .setInputCol(tokenizer.getOutputCol)\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "val rf = new RandomForestClassifier()\n",
    "    .setLabelCol(\"label\")\n",
    "    .setFeaturesCol(\"features\")\n",
    "    .setNumTrees(10)\n",
    "\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, hashingTF, rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a ParamGridBuilder to construct a grid of parameters to search over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paramGrid = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array({\n",
       "\trfc_c5d3f6700f16-maxDepth: 5,\n",
       "\trfc_c5d3f6700f16-numTrees: 20\n",
       "}, {\n",
       "\trfc_c5d3f6700f16-maxDepth: 5,\n",
       "\trfc_c5d3f6700f16-numTrees: 50\n",
       "}, {\n",
       "\trfc_c5d3f6700f16-maxDepth: 10,\n",
       "\trfc_c5d3f6700f16-numTrees: 20\n",
       "}, {\n",
       "\trfc_c5d3f6700f16-maxDepth: 10,\n",
       "\trfc_c5d3f6700f16-numTrees: 50\n",
       "})\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n",
    "\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(rf.maxDepth, Array(5, 10))\n",
    "  .addGrid(rf.numTrees, Array(20, 50))\n",
    "  .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TrainValidationSplit will try all combinations of values and determine best model using the evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainValidationSplit = tvs_96c9401d91cd\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tvs_96c9401d91cd"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "\n",
    "val trainValidationSplit = new TrainValidationSplit()\n",
    "  .setEstimator(pipeline)\n",
    "  .setEvaluator(new BinaryClassificationEvaluator)\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  // 80% of the data will be used for training and the remaining 20% for validation.\n",
    "  .setTrainRatio(0.8)\n",
    "  // Evaluate up to 2 parameter settings in parallel\n",
    "  .setParallelism(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run train validation split, and choose the best set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model = pipeline_e9786cc35e88\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_e9786cc35e88"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = trainValidationSplit.fit(training).bestModel.asInstanceOf[PipelineModel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look on params for our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "\trfc_c5d3f6700f16-cacheNodeIds: false,\n",
       "\trfc_c5d3f6700f16-checkpointInterval: 10,\n",
       "\trfc_c5d3f6700f16-featureSubsetStrategy: auto,\n",
       "\trfc_c5d3f6700f16-featuresCol: features,\n",
       "\trfc_c5d3f6700f16-impurity: gini,\n",
       "\trfc_c5d3f6700f16-labelCol: label,\n",
       "\trfc_c5d3f6700f16-maxBins: 32,\n",
       "\trfc_c5d3f6700f16-maxDepth: 10,\n",
       "\trfc_c5d3f6700f16-maxMemoryInMB: 256,\n",
       "\trfc_c5d3f6700f16-minInfoGain: 0.0,\n",
       "\trfc_c5d3f6700f16-minInstancesPerNode: 1,\n",
       "\trfc_c5d3f6700f16-numTrees: 50,\n",
       "\trfc_c5d3f6700f16-predictionCol: prediction,\n",
       "\trfc_c5d3f6700f16-probabilityCol: probability,\n",
       "\trfc_c5d3f6700f16-rawPredictionCol: rawPrediction,\n",
       "\trfc_c5d3f6700f16-seed: 207336481,\n",
       "\trfc_c5d3f6700f16-subsamplingRate: 1.0\n",
       "}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.stages(2).asInstanceOf[RandomForestClassificationModel].extractParamMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getProbability = UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val getProbability = udf((prediction: org.apache.spark.ml.linalg.Vector) => prediction(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+----------+\n",
      "|               tweet|label|  clean_probability|prediction|\n",
      "+--------------------+-----+-------------------+----------+\n",
      "|      My current ...|    0|0.45799854653578903|       0.0|\n",
      "|     I dont like ...|    0|0.47154405148038614|       0.0|\n",
      "|  Jus Got Hom Fr....|    0| 0.4388917102765312|       0.0|\n",
      "|  in cab headed t...|    0| 0.5341072869493625|       1.0|\n",
      "|  now the pic won...|    0| 0.5360566658737981|       1.0|\n",
      "|             over it|    0| 0.5308792350458302|       1.0|\n",
      "|  went to maggie'...|    0|  0.447332356227742|       0.0|\n",
      "| ... had weird en...|    0|  0.513398097735378|       1.0|\n",
      "|      ... that's all|    0| 0.5358657398890049|       1.0|\n",
      "| .... Life can be...|    0| 0.4628345037954727|       0.0|\n",
      "|          @I_am_delo|    0| 0.5358657398890049|       1.0|\n",
      "| Archie's annoyin...|    0| 0.5014728836966545|       1.0|\n",
      "| Argh, the speake...|    0| 0.4720658465457641|       0.0|\n",
      "| B- in genetics s...|    0|0.43747428231128466|       0.0|\n",
      "| Cute kitten is g...|    0| 0.5207870148414039|       1.0|\n",
      "| Damn. This kinda...|    0| 0.4688186001574966|       0.0|\n",
      "|       HATES ITUNES.|    0| 0.5327641576135786|       1.0|\n",
      "| Have to leave to...|    0|0.39122542932500853|       0.0|\n",
      "| I Still Cant Fin...|    0|0.40140421768852047|       0.0|\n",
      "| I don't think my...|    0|0.44018586129214143|       0.0|\n",
      "+--------------------+-----+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "testResult = [label: int, tweet: string ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string ... 5 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val testResult = model.transform(test)\n",
    "\n",
    "testResult.select($\"tweet\", $\"label\", getProbability($\"probability\").alias(\"clean_probability\"), $\"prediction\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bce = binEval_ad71352aba2c\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7231869604660494"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bce = new BinaryClassificationEvaluator()\n",
    "    .setLabelCol(\"label\")\n",
    "    .setMetricName(\"areaUnderROC\")\n",
    "    .setRawPredictionCol(\"probability\")\n",
    "\n",
    "bce.evaluate(testResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC = 0.72 - Good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write.overwrite().save(\"/home/jovyan/models/spark-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sameModel = pipeline_e9786cc35e88\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_e9786cc35e88"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sameModel = PipelineModel.load(\"/home/jovyan/models/spark-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|               tweet|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    0|@switchfoot http:...|[@switchfoot, htt...|(1000,[7,14,21,54...|[21.0526438619503...|[0.42105287723900...|       1.0|\n",
      "|    0|is upset that he ...|[is, upset, that,...|(1000,[170,193,22...|[25.0385188841850...|[0.50077037768370...|       0.0|\n",
      "|    0|@Kenichan I dived...|[@kenichan, i, di...|(1000,[10,36,77,1...|[29.3783772814382...|[0.58756754562876...|       0.0|\n",
      "|    0|my whole body fee...|[my, whole, body,...|(1000,[82,191,296...|[25.5832912735477...|[0.51166582547095...|       0.0|\n",
      "|    0|@nationwideclass ...|[@nationwideclass...|(1000,[18,96,130,...|[27.4134510551815...|[0.54826902110363...|       0.0|\n",
      "|    0|@Kwesidei not the...|[@kwesidei, not, ...|(1000,[18,223,710...|[25.6095853042468...|[0.51219170608493...|       0.0|\n",
      "|    0|         Need a hug |      [need, a, hug]|(1000,[48,170,537...|[23.7394669101269...|[0.47478933820253...|       1.0|\n",
      "|    0|@LOLTrish hey  lo...|[@loltrish, hey, ...|(1000,[139,157,17...|[21.1786314212128...|[0.42357262842425...|       1.0|\n",
      "|    0|@Tatiana_K nope t...|[@tatiana_k, nope...|(1000,[48,234,299...|[24.8664922968148...|[0.49732984593629...|       1.0|\n",
      "|    0|@twittera que me ...|[@twittera, que, ...|(1000,[161,324,47...|[23.4337720555628...|[0.46867544111125...|       1.0|\n",
      "|    0|spring break in p...|[spring, break, i...|(1000,[13,193,301...|[23.2804707735634...|[0.46560941547126...|       1.0|\n",
      "|    0|I just re-pierced...|[i, just, re-pier...|(1000,[307,329,47...|[27.0926706558457...|[0.54185341311691...|       0.0|\n",
      "|    0|@caregiving I cou...|[@caregiving, i, ...|(1000,[56,202,234...|[28.1246393810318...|[0.56249278762063...|       0.0|\n",
      "|    0|@octolinz16 It it...|[@octolinz16, it,...|(1000,[126,230,32...|[23.9657857614580...|[0.47931571522916...|       1.0|\n",
      "|    0|@smarrison i woul...|[@smarrison, i, w...|(1000,[18,83,170,...|[29.5553089796302...|[0.59110617959260...|       0.0|\n",
      "|    0|@iamjazzyfizzle I...|[@iamjazzyfizzle,...|(1000,[7,71,202,2...|[27.9910967800734...|[0.55982193560146...|       0.0|\n",
      "|    0|Hollis' death sce...|[hollis', death, ...|(1000,[2,3,18,82,...|[27.2369374151194...|[0.54473874830238...|       0.0|\n",
      "|    0|about to file taxes |[about, to, file,...|(1000,[108,388,48...|[23.8243481535037...|[0.47648696307007...|       1.0|\n",
      "|    0|@LettyA ahh ive a...|[@lettya, ahh, iv...|(1000,[13,107,201...|[20.7406284152657...|[0.41481256830531...|       1.0|\n",
      "|    0|@FakerPattyPattz ...|[@fakerpattypattz...|(1000,[53,102,154...|[19.9676220436293...|[0.39935244087258...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictionsDF = [label: int, tweet: string ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string ... 5 more fields]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictionsDF = sameModel.transform(raw_sentiment)\n",
    "predictionsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+----------+\n",
      "|               tweet|label|  clean_probability|prediction|\n",
      "+--------------------+-----+-------------------+----------+\n",
      "|@switchfoot http:...|    0| 0.5789471227609927|       1.0|\n",
      "|is upset that he ...|    0| 0.4992296223162992|       0.0|\n",
      "|@Kenichan I dived...|    0|0.41243245437123427|       0.0|\n",
      "|my whole body fee...|    0|0.48833417452904576|       0.0|\n",
      "|@nationwideclass ...|    0| 0.4517309788963685|       0.0|\n",
      "|@Kwesidei not the...|    0| 0.4878082939150626|       0.0|\n",
      "|         Need a hug |    0| 0.5252106617974605|       1.0|\n",
      "|@LOLTrish hey  lo...|    0| 0.5764273715757433|       1.0|\n",
      "|@Tatiana_K nope t...|    0| 0.5026701540637027|       1.0|\n",
      "|@twittera que me ...|    0| 0.5313245588887434|       1.0|\n",
      "|spring break in p...|    0| 0.5343905845287309|       1.0|\n",
      "|I just re-pierced...|    0| 0.4581465868830846|       0.0|\n",
      "|@caregiving I cou...|    0| 0.4375072123793634|       0.0|\n",
      "|@octolinz16 It it...|    0| 0.5206842847708398|       1.0|\n",
      "|@smarrison i woul...|    0| 0.4088938204073947|       0.0|\n",
      "|@iamjazzyfizzle I...|    0|0.44017806439853197|       0.0|\n",
      "|Hollis' death sce...|    0| 0.4552612516976118|       0.0|\n",
      "|about to file taxes |    0| 0.5235130369299251|       1.0|\n",
      "|@LettyA ahh ive a...|    0| 0.5851874316946846|       1.0|\n",
      "|@FakerPattyPattz ...|    0| 0.6006475591274135|       1.0|\n",
      "+--------------------+-----+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsDF\n",
    "    .select($\"tweet\", $\"label\", getProbability($\"probability\").alias(\"clean_probability\"), $\"prediction\")\n",
    "    .show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
